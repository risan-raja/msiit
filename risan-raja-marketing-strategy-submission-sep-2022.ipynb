{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npd.options.display.max_columns = 90\nimport copy\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-22T10:44:17.979953Z","iopub.execute_input":"2022-09-22T10:44:17.980534Z","iopub.status.idle":"2022-09-22T10:44:17.993986Z","shell.execute_reply.started":"2022-09-22T10:44:17.980497Z","shell.execute_reply":"2022-09-22T10:44:17.992522Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"/kaggle/input/marketing-strategy-personalised-offer/sample.csv\n/kaggle/input/marketing-strategy-personalised-offer/train_data.csv\n/kaggle/input/marketing-strategy-personalised-offer/test_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"data  = pd.read_csv('/kaggle/input/marketing-strategy-personalised-offer/train_data.csv')\neval_data = pd.read_csv('/kaggle/input/marketing-strategy-personalised-offer/test_data.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-22T07:59:17.803921Z","iopub.execute_input":"2022-09-22T07:59:17.804319Z","iopub.status.idle":"2022-09-22T07:59:17.902207Z","shell.execute_reply.started":"2022-09-22T07:59:17.804289Z","shell.execute_reply":"2022-09-22T07:59:17.901060Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Convert days to Hours","metadata":{}},{"cell_type":"code","source":"data  = pd.read_csv('/kaggle/input/marketing-strategy-personalised-offer/train_data.csv')\neval_data = pd.read_csv('/kaggle/input/marketing-strategy-personalised-offer/test_data.csv')\ndef convert_to_hours(row):\n    if \"hours\" in row['offer expiration']:\n        row['offer expiration'] = int(row['offer expiration'][:-5])\n    elif \"days\" in row['offer expiration']:\n        row['offer expiration'] = int(row['offer expiration'][:-4])*24\n    return row\ndef save_data():\n    global data, eval_data\n    data.to_parquet('data.parquet')\n    eval_data.to_parquet('eval_data.parquet')\n\ndata = data.apply(convert_to_hours,axis=1)\neval_data = eval_data.apply(convert_to_hours,axis=1)\ndef pythonise_col_names(df: pd.DataFrame):\n    col_names = list(df.columns)\n    rename_stubs = {}\n    for x in col_names:\n        if x == 'Offer Accepted':\n            r = 'target'\n            rename_stubs[x]=r\n        elif \"/\" in x:\n            r = x.split('/')[1]\n            r = r.replace(' ','_').lower()\n            rename_stubs[x]=r\n        elif \"-\" in x:\n            r = x.replace('-','_').lower()\n            r = r.replace(' ','_').lower()\n            rename_stubs[x]=r\n        elif \" \" in x:\n            r = x.replace(' ','_').lower()\n            rename_stubs[x]=r\n        else:\n            r = x.lower()\n            rename_stubs[x] = r \n    return rename_stubs\ndata.rename(pythonise_col_names(data), inplace=True,axis=1)\neval_data.rename(pythonise_col_names(eval_data), inplace=True,axis=1)\n\nages_ord = ['below21','21', '26', '31', '36', '41', '46', '50plus']\nordinal_age_codes =  {x: idx for idx, x in enumerate(ages_ord)}\nincome_codes = { \n    'Less than ₹12500':1,\n    '₹12500 - ₹24999' :2,\n    '₹25000 - ₹37499' :3,\n    '₹37500 - ₹49999' :4,\n    '₹50000 - ₹62499' :5,\n    '₹62500 - ₹74999' :6,\n    '₹75000 - ₹87499' :7,\n    '₹87500 - ₹99999' :8,\n    '₹100000 or More' :9,\n}\n\ndata['ordinal__income_range'] = 0\neval_data['ordinal__income_range'] = 0\ndata['ordinal__age'] = 0\neval_data['ordinal__age'] = 0\n\ndef codify_special_ordinal_range(row):\n    global income_codes, ordinal_age_codes\n    row['ordinal__income_range'] = income_codes[row['income_range']]\n    row['ordinal__age'] = ordinal_age_codes[row['age']]\n    return row\ndata = data.apply(codify_special_ordinal_range,axis=1)\neval_data = eval_data.apply(codify_special_ordinal_range,axis=1)\n\nordinal_category_codes = {\n    '4~8': 3,\n    'less1': 1,\n    'never': 0,\n    '1~3': 2,\n    'gt8': 4,\n    np.nan: np.nan}\n\n# data = data.apply(codify_cold_drink_consumption,axis=1)\n# eval_data = eval_data.apply(codify_cold_drink_consumption,axis=1)\nord_cols = [\"restaur_spend_less_than20\",\"no_take_aways\",\"restaur_spend_greater_than20\",\"no_visited_bars\",\"no_visited_cold_drinks\"]\ncol_ord_names = [\"ordinal__\" + x for x in ord_cols]\ndata[col_ord_names] = 0\neval_data[col_ord_names] = 0\ndef codify_ordinal_columns(row):\n    global col_ord_names, ordinal_category_codes, ord_cols\n    for ord_col,col_ord_name in zip(ord_cols,col_ord_names):\n        try:\n            row[col_ord_name] = int(ordinal_category_codes[row[ord_col]])\n        except ValueError:\n            row[col_ord_name] = ordinal_category_codes[row[ord_col]]\n    return row\ndata = data.apply(codify_ordinal_columns,axis=1)\neval_data = eval_data.apply(codify_ordinal_columns,axis=1)\n\n\"\"\"\nCar Feature:\nLabel NaN as unknown for now\n\"\"\"\ndata.car.fillna(\"unknown\",inplace=True)\neval_data.car.fillna(\"unknown\",inplace=True)\n\nnominal_cs = ['restaurant_type','marital_status','climate',\"drop_location\",\"job_industry\",\"gender\",\"customer_type\",\"car\"]\nnominal_col_names = [\"nominal__\" + x for x in nominal_cs]\nmaster_nominals= pd.concat([data[nominal_cs],eval_data[nominal_cs]], ignore_index=True,axis=0)\nnominal_encoder = {nc:{} for nc in nominal_cs}\nfor c in nominal_cs:\n    unique_vals = list(master_nominals[c].unique())\n    nominal_codes = {x: idx for idx, x in enumerate(unique_vals)}\n    nominal_encoder[c] = nominal_codes\ndata[nominal_col_names] = 0\neval_data[nominal_col_names] = 0\ndef codify_nominal_columns(row):\n    global nominal_col_names, nominal_encoder, nominal_cs\n    for nom_col,col_nom_name in zip(nominal_cs,nominal_col_names):\n        try:\n            row[col_nom_name] = int(nominal_encoder[nom_col][row[nom_col]])\n        except ValueError:\n            row[col_nom_name] = nominal_encoder[nom_col][row[nom_col]]\n    return row\ndata = data.apply(codify_nominal_columns,axis=1)\neval_data = eval_data.apply(codify_nominal_columns,axis=1)\n\ndef drop_const_and_enc_columns(df):\n    cols_to_drop = [\n        'restaur_spend_less_than20',\n        'no_take_aways',\n        'restaur_spend_greater_than20',\n        'no_visited_bars',\n        'no_visited_cold_drinks',\n        'restaurant_type',\n        'marital_status',\n        'climate',\n        'drop_location',\n        'job_industry',\n        'gender',\n        'customer_type',\n        'car',\n        'income_range',\n        \"travelled_more_than_5mins_for_offer\",\n        'age'\n    ]\n    df = df.drop(cols_to_drop,axis=1)\n    return df\ndata = drop_const_and_enc_columns(data)\neval_data = drop_const_and_enc_columns(eval_data)\n\ndata_original_col_order = [\n    'offer_expiration',\n    'ordinal__income_range',\n    'ordinal__no_visited_cold_drinks',\n    'travelled_more_than_15mins_for_offer',\n    'ordinal__restaur_spend_less_than20',\n    'nominal__marital_status',\n    'nominal__restaurant_type',\n    'ordinal__age',\n    'prefer_western_over_chinese',\n    'travelled_more_than_25mins_for_offer',\n    'ordinal__no_visited_bars',\n    'nominal__gender',\n    'nominal__car',\n    'restuarant_same_direction_house',\n    'cooks_regularly',\n    'nominal__customer_type',\n    'qualification',\n    'is_foodie',\n    'ordinal__no_take_aways',\n    'nominal__job_industry',\n    'restuarant_opposite_direction_house',\n    'has_children',\n    'visit_restaurant_with_rating_(avg)',\n    'temperature',\n    'ordinal__restaur_spend_greater_than20',\n    'travel_time',\n    'nominal__climate',\n    'nominal__drop_location',\n    'prefer_home_food',\n    'target'\n]\neval_data_original_col_order = copy.deepcopy(data_original_col_order)\neval_data_original_col_order.remove('target')\n\ndata = data.loc[:,data_original_col_order]\neval_data = eval_data.loc[:,eval_data_original_col_order]\nsave_data()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T10:46:47.718234Z","iopub.execute_input":"2022-09-22T10:46:47.718627Z","iopub.status.idle":"2022-09-22T10:46:59.283300Z","shell.execute_reply.started":"2022-09-22T10:46:47.718597Z","shell.execute_reply":"2022-09-22T10:46:59.282091Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}