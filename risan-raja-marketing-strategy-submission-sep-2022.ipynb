{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896b925",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.023308,
     "end_time": "2022-09-22T12:45:30.854323",
     "exception": false,
     "start_time": "2022-09-22T12:45:30.831015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import copy\n",
    "from sklearnex import patch_sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import (\n",
    "    BackwardDifferenceEncoder,\n",
    "    BaseNEncoder,\n",
    "    BinaryEncoder,\n",
    "    CatBoostEncoder,\n",
    "    CountEncoder,\n",
    "    GLMMEncoder,\n",
    "    HelmertEncoder,\n",
    "    JamesSteinEncoder,\n",
    "    LeaveOneOutEncoder,\n",
    "    MEstimateEncoder,\n",
    "    SummaryEncoder,\n",
    "    TargetEncoder,\n",
    "    WOEEncoder,\n",
    ")\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import set_config\n",
    "from sklearn.base import clone as model_clone\n",
    "from sklearn.cluster import *\n",
    "from sklearn.impute import *\n",
    "from sklearn.compose import *\n",
    "from sklearn.cross_decomposition import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.gaussian_process import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.multioutput import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.kernel_approximation import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.utils import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.semi_supervised import *\n",
    "from sklearn.discriminant_analysis import *\n",
    "from sklearn.covariance import *\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.calibration import *\n",
    "import joblib\n",
    "from pprint import pprint as pp\n",
    "\n",
    "pd.options.compute.use_numba = True\n",
    "pd.options.compute.use_numexpr = True\n",
    "pd.options.compute.use_bottleneck = True\n",
    "pd.options.display.max_columns = 90\n",
    "set_config(display=\"diagram\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from imblearn.over_sampling import (\n",
    "    ADASYN,\n",
    "    SMOTE,\n",
    "    RandomOverSampler,\n",
    "    SVMSMOTE,\n",
    "    SMOTENC,\n",
    "    SMOTEN,\n",
    "    BorderlineSMOTE,\n",
    "    KMeansSMOTE,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "from joblib import parallel_backend\n",
    "from joblib.memory import Memory\n",
    "\n",
    "# patch_sklearn()\n",
    "KAGGLE_ENV = 1\n",
    "DATA_INPUT = \"/kaggle/input/marketing-strategy-personalised-offer/\"\n",
    "DATA_OUTPUT = \"/kaggle/working/\"\n",
    "cwd = os.path.abspath(os.getcwd())\n",
    "if \"mlop3n/Pycharm\" in cwd or \"u164131\" in cwd:\n",
    "    KAGGLE_ENV = 0\n",
    "    DATA_INPUT = \"kaggle/input/marketing-strategy-personalised-offer/\"\n",
    "    DATA_OUTPUT = \"kaggle/working/\"\n",
    "CACHE = Memory(DATA_OUTPUT + \"joblib\", verbose=0)\n",
    "patch_sklearn()\n",
    "\n",
    "data = pd.read_csv(DATA_INPUT + \"train_data.csv\")\n",
    "eval_data = pd.read_csv(DATA_INPUT + \"test_data.csv\")\n",
    "\n",
    "def gen_train_test(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=10\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def quick_test(X):\n",
    "    clfs = [\n",
    "        RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=42),\n",
    "        DecisionTreeClassifier(class_weight=\"balanced\", random_state=42),\n",
    "        HistGradientBoostingClassifier(random_state=42),\n",
    "        LogisticRegressionCV(max_iter=10000, class_weight=\"balanced\", random_state=42),\n",
    "    ]\n",
    "    y = data.target\n",
    "    X_train, X_test, y_train, y_test = gen_train_test(X, y, test_size=0.5)\n",
    "    for clf in clfs:\n",
    "        y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "        score = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        print(f\"{clf.__class__.__name__} :: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3eefd0",
   "metadata": {
    "papermill": {
     "duration": 0.205848,
     "end_time": "2022-09-22T12:45:31.063261",
     "exception": false,
     "start_time": "2022-09-22T12:45:30.857413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = data.isna().sum().plot(kind=\"bar\", rot=90, logy=True, figsize=(10,8))\n",
    "data.nunique()\n",
    "n_c= [\"Job/Job Industry\",\"Marital Status\",\"restaurant type\",\"Customer type\",\"Climate\",\"Qualification\",\"drop location\",\"car\"]\n",
    "# for c in n_c:\n",
    "#     print(c,\"\\t:\\t\",data[c].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40fb97-f7dd-4911-95bc-3f78f7f0af61",
   "metadata": {},
   "source": [
    "```text\n",
    "Job/Job Industry \t:\t ['Unemployed' 'Arts Design Entertainment Sports & Media' 'Sales & Related'\n",
    " 'Student' 'Business & Financial' 'Computer & Mathematical'\n",
    " 'Office & Administrative Support' 'Management' 'Healthcare Support'\n",
    " 'Life Physical Social Science' 'Installation Maintenance & Repair'\n",
    " 'Legal' 'Community & Social Services' 'Education&Training&Library'\n",
    " 'Construction & Extraction' 'Healthcare Practitioners & Technical'\n",
    " 'Transportation & Material Moving' 'Retired' 'Architecture & Engineering'\n",
    " 'Production Occupations' 'Farming Fishing & Forestry'\n",
    " 'Protective Service' 'Personal Care & Service'\n",
    " 'Food Preparation & Serving Related'\n",
    " 'Building & Grounds Cleaning & Maintenance'] \n",
    "\n",
    "Marital Status \t:\t ['Married partner' 'Single' 'Divorced' 'Unmarried partner' 'Widowed'] \n",
    "\n",
    "restaurant type \t:\t ['4 star restaurant' 'Take-away restaurant' 'Cold drinks'\n",
    " 'Restaurant with pub' '2 star restaurant'] \n",
    "\n",
    "Customer type \t:\t ['Individual' 'With Family' 'With Kids' 'With Colleagues'] \n",
    "\n",
    "Climate \t:\t ['Spring' 'Summer' 'Winter'] \n",
    "\n",
    "Qualification \t:\t ['Bachelors degree' 'Some college - no degree'\n",
    " 'Graduate degree (Masters or Doctorate)' 'Associates degree'\n",
    " 'High School Graduate' 'Some High School'] \n",
    "\n",
    "drop location \t:\t ['Location B' 'Location A' 'Location C'] \n",
    "\n",
    "car \t:\t [nan 'Mazda5' 'Car that is too old to install Onstar :D' 'crossover'\n",
    " 'Scooter and motorcycle' 'do not drive'] \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59469af",
   "metadata": {
    "papermill": {
     "duration": 0.002514,
     "end_time": "2022-09-22T12:45:31.068578",
     "exception": false,
     "start_time": "2022-09-22T12:45:31.066064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Cleaning If possible Reload Last Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818cc1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 14.904815,
     "end_time": "2022-09-22T12:45:45.975943",
     "exception": false,
     "start_time": "2022-09-22T12:45:31.071128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_INPUT + \"train_data.csv\")\n",
    "eval_data = pd.read_csv(DATA_INPUT + \"test_data.csv\")\n",
    "ques = \"Do you want to use new data?\"\n",
    "ans = input(prompt=ques)\n",
    "if ans.lower() == \"y\":\n",
    "\n",
    "    def convert_to_hours(row):\n",
    "        if \"hours\" in row[\"offer expiration\"]:\n",
    "            #         row['offer expiration'] = int(row['offer expiration'][:-5])\n",
    "            row[\"offer expiration\"] = 0\n",
    "        elif \"days\" in row[\"offer expiration\"]:\n",
    "            #         row['offer expiration'] = int(row['offer expiration'][:-4])*24\n",
    "            row[\"offer expiration\"] = 1\n",
    "        return row\n",
    "\n",
    "    def save_data():\n",
    "        global data, eval_data\n",
    "        data.to_parquet(DATA_OUTPUT + \"data.parquet\")\n",
    "        eval_data.to_parquet(DATA_OUTPUT + \"eval_data.parquet\")\n",
    "\n",
    "    data = data.apply(convert_to_hours, axis=1)\n",
    "    eval_data = eval_data.apply(convert_to_hours, axis=1)\n",
    "\n",
    "    def pythonise_col_names(df: pd.DataFrame):\n",
    "        col_names = list(df.columns)\n",
    "        rename_stubs = {}\n",
    "        for x in col_names:\n",
    "            if x == \"Offer Accepted\":\n",
    "                r = \"target\"\n",
    "                rename_stubs[x] = r\n",
    "            elif \"/\" in x:\n",
    "                r = x.split(\"/\")[1]\n",
    "                r = r.replace(\" \", \"_\").lower()\n",
    "                rename_stubs[x] = r\n",
    "            elif \"-\" in x:\n",
    "                r = x.replace(\"-\", \"_\").lower()\n",
    "                r = r.replace(\" \", \"_\").lower()\n",
    "                rename_stubs[x] = r\n",
    "            elif \" \" in x:\n",
    "                r = x.replace(\" \", \"_\").lower()\n",
    "                rename_stubs[x] = r\n",
    "            else:\n",
    "                r = x.lower()\n",
    "                rename_stubs[x] = r\n",
    "        return rename_stubs\n",
    "\n",
    "    data.rename(pythonise_col_names(data), inplace=True, axis=1)\n",
    "    eval_data.rename(pythonise_col_names(eval_data), inplace=True, axis=1)\n",
    "    gender_code = {\"Male\": 0, \"Female\": 1}\n",
    "\n",
    "    def binarize_gender(row):\n",
    "        global gender_code\n",
    "        row[\"gender\"] = gender_code[row[\"gender\"]]\n",
    "        return row\n",
    "\n",
    "    data = data.apply(binarize_gender, axis=1)\n",
    "    eval_data = eval_data.apply(binarize_gender, axis=1)\n",
    "\n",
    "    ages_ord = [\"below21\", \"21\", \"26\", \"31\", \"36\", \"41\", \"46\", \"50plus\"]\n",
    "    ordinal_age_codes = {x: idx for idx, x in enumerate(ages_ord)}\n",
    "    income_codes = {\n",
    "        \"Less than ₹12500\": 1,\n",
    "        \"₹12500 - ₹24999\": 2,\n",
    "        \"₹25000 - ₹37499\": 3,\n",
    "        \"₹37500 - ₹49999\": 4,\n",
    "        \"₹50000 - ₹62499\": 5,\n",
    "        \"₹62500 - ₹74999\": 6,\n",
    "        \"₹75000 - ₹87499\": 7,\n",
    "        \"₹87500 - ₹99999\": 8,\n",
    "        \"₹100000 or More\": 9,\n",
    "    }\n",
    "    ordinal_quali_codes = {'Bachelors degree':4,\n",
    "     'Some college - no degree':2,\n",
    "     'Graduate degree (Masters or Doctorate)':5,\n",
    "     'Associates degree':3,\n",
    "     'High School Graduate':1,\n",
    "     'Some High School':0\n",
    "    }\n",
    "    data[\"ordinal__income_range\"] = 0\n",
    "    eval_data[\"ordinal__income_range\"] = 0\n",
    "    data[\"ordinal__age\"] = 0\n",
    "    eval_data[\"ordinal__age\"] = 0\n",
    "    data['ordinal__qualif'] =0\n",
    "    eval_data['ordinal__qualif'] =0\n",
    "    def codify_special_ordinal_range(row):\n",
    "        global income_codes, ordinal_age_codes\n",
    "        row[\"ordinal__income_range\"] = income_codes[row[\"income_range\"]]\n",
    "        row[\"ordinal__age\"] = ordinal_age_codes[row[\"age\"]]\n",
    "        row[\"ordinal__qualif\"] = ordinal_quali_codes[row[\"qualification\"]]\n",
    "        return row\n",
    "\n",
    "    data = data.apply(codify_special_ordinal_range, axis=1)\n",
    "    eval_data = eval_data.apply(codify_special_ordinal_range, axis=1)\n",
    "\n",
    "    ordinal_category_codes = {\n",
    "        \"4~8\": 3,\n",
    "        \"less1\": 1,\n",
    "        \"never\": 0,\n",
    "        \"1~3\": 2,\n",
    "        \"gt8\": 4,\n",
    "        np.nan: np.nan,\n",
    "    }\n",
    "\n",
    "    # data = data.apply(codify_cold_drink_consumption,axis=1)\n",
    "    # eval_data = eval_data.apply(codify_cold_drink_consumption,axis=1)\n",
    "    ord_cols = [\n",
    "        \"restaur_spend_less_than20\",\n",
    "        \"no_take_aways\",\n",
    "        \"restaur_spend_greater_than20\",\n",
    "        \"no_visited_bars\",\n",
    "        \"no_visited_cold_drinks\",\n",
    "    ]\n",
    "    col_ord_names = [\"ordinal__\" + x for x in ord_cols]\n",
    "    data[col_ord_names] = 0\n",
    "    eval_data[col_ord_names] = 0\n",
    "\n",
    "    def codify_ordinal_columns(row):\n",
    "        global col_ord_names, ordinal_category_codes, ord_cols\n",
    "        for ord_col, col_ord_name in zip(ord_cols, col_ord_names):\n",
    "            try:\n",
    "                row[col_ord_name] = int(ordinal_category_codes[row[ord_col]])\n",
    "            except ValueError:\n",
    "                row[col_ord_name] = ordinal_category_codes[row[ord_col]]\n",
    "        return row\n",
    "\n",
    "    data = data.apply(codify_ordinal_columns, axis=1)\n",
    "    eval_data = eval_data.apply(codify_ordinal_columns, axis=1)\n",
    "\n",
    "    \"\"\"\n",
    "    Car Feature:\n",
    "    Label NaN as unknown for now\n",
    "    \"\"\"\n",
    "    data.car.fillna(\"unknown\", inplace=True)\n",
    "    eval_data.car.fillna(\"unknown\", inplace=True)\n",
    "\n",
    "    nominal_cs = [\n",
    "        \"restaurant_type\",\n",
    "        \"marital_status\",\n",
    "        \"climate\",\n",
    "        \"drop_location\",\n",
    "        \"job_industry\",\n",
    "        \"customer_type\",\n",
    "        \"car\",\n",
    "    ]\n",
    "    nominal_col_names = [\"nominal__\" + x for x in nominal_cs]\n",
    "    master_nominals = pd.concat(\n",
    "        [data[nominal_cs], eval_data[nominal_cs]], ignore_index=True, axis=0\n",
    "    )\n",
    "    nominal_encoder = {nc: {} for nc in nominal_cs}\n",
    "    for c in nominal_cs:\n",
    "        unique_vals = list(master_nominals[c].unique())\n",
    "        nominal_codes = {x: idx for idx, x in enumerate(unique_vals)}\n",
    "        nominal_encoder[c] = nominal_codes\n",
    "    data[nominal_col_names] = 0\n",
    "    eval_data[nominal_col_names] = 0\n",
    "\n",
    "    def codify_nominal_columns(row):\n",
    "        global nominal_col_names, nominal_encoder, nominal_cs\n",
    "        for nom_col, col_nom_name in zip(nominal_cs, nominal_col_names):\n",
    "            try:\n",
    "                row[col_nom_name] = int(nominal_encoder[nom_col][row[nom_col]])\n",
    "            except ValueError:\n",
    "                row[col_nom_name] = nominal_encoder[nom_col][row[nom_col]]\n",
    "        return row\n",
    "\n",
    "    data = data.apply(codify_nominal_columns, axis=1)\n",
    "    eval_data = eval_data.apply(codify_nominal_columns, axis=1)\n",
    "\n",
    "    def drop_const_and_enc_columns(df):\n",
    "        cols_to_drop = [\n",
    "            \"restaur_spend_less_than20\",\n",
    "            \"no_take_aways\",\n",
    "            \"restaur_spend_greater_than20\",\n",
    "            \"no_visited_bars\",\n",
    "            \"no_visited_cold_drinks\",\n",
    "            \"restaurant_type\",\n",
    "            \"marital_status\",\n",
    "            \"climate\",\n",
    "            \"qualification\",\n",
    "            \"drop_location\",\n",
    "            \"job_industry\",\n",
    "            \"customer_type\",\n",
    "            \"car\",\n",
    "            \"income_range\",\n",
    "            \"travelled_more_than_5mins_for_offer\",\n",
    "            \"age\",\n",
    "        ]\n",
    "        df = df.drop(cols_to_drop, axis=1)\n",
    "        return df\n",
    "\n",
    "    data = drop_const_and_enc_columns(data)\n",
    "    eval_data = drop_const_and_enc_columns(eval_data)\n",
    "\n",
    "    data_original_col_order = [\n",
    "        \"offer_expiration\",\n",
    "        \"ordinal__income_range\",\n",
    "        \"ordinal__no_visited_cold_drinks\",\n",
    "        \"travelled_more_than_15mins_for_offer\",\n",
    "        \"ordinal__restaur_spend_less_than20\",\n",
    "        \"nominal__marital_status\",\n",
    "        \"nominal__restaurant_type\",\n",
    "        \"ordinal__age\",\n",
    "        \"prefer_western_over_chinese\",\n",
    "        \"travelled_more_than_25mins_for_offer\",\n",
    "        \"ordinal__no_visited_bars\",\n",
    "        \"gender\",\n",
    "        \"nominal__car\",\n",
    "        \"restuarant_same_direction_house\",\n",
    "        \"cooks_regularly\",\n",
    "        \"nominal__customer_type\",\n",
    "        \"ordinal__qualif\",\n",
    "        \"is_foodie\",\n",
    "        \"ordinal__no_take_aways\",\n",
    "        \"nominal__job_industry\",\n",
    "        \"restuarant_opposite_direction_house\",\n",
    "        \"has_children\",\n",
    "        \"visit_restaurant_with_rating_(avg)\",\n",
    "        \"temperature\",\n",
    "        \"ordinal__restaur_spend_greater_than20\",\n",
    "        \"travel_time\",\n",
    "        \"nominal__climate\",\n",
    "        \"nominal__drop_location\",\n",
    "        \"prefer_home_food\",\n",
    "        \"target\",\n",
    "    ]\n",
    "    eval_data_original_col_order = copy.deepcopy(data_original_col_order)\n",
    "    eval_data_original_col_order.remove(\"target\")\n",
    "\n",
    "    data = data.loc[:, data_original_col_order]\n",
    "    eval_data = eval_data.loc[:, eval_data_original_col_order]\n",
    "    binary_features = [\n",
    "        \"offer_expiration\",\n",
    "        \"travelled_more_than_15mins_for_offer\",\n",
    "        \"prefer_western_over_chinese\",\n",
    "        \"travelled_more_than_25mins_for_offer\",\n",
    "        \"restuarant_same_direction_house\",\n",
    "        \"cooks_regularly\",\n",
    "        \"is_foodie\",\n",
    "        \"restuarant_opposite_direction_house\",\n",
    "        \"has_children\",\n",
    "        \"prefer_home_food\",\n",
    "        \"gender\",\n",
    "    ]\n",
    "    b_f_rn = {x: \"binary__\" + x for x in binary_features}\n",
    "    data.rename(b_f_rn, axis=1, inplace=True)\n",
    "    eval_data.rename(b_f_rn, axis=1, inplace=True)\n",
    "    remaining_ordinals = {\n",
    "        \"visit_restaurant_with_rating_(avg)\": \"ordinal__rest_rating\",\n",
    "        \"temperature\": \"ordinal__temperature\",\n",
    "        \"travel_time\": \"ordinal__travel_time\",\n",
    "    }\n",
    "\n",
    "    def rename_remaining_ord(df):\n",
    "        df = df.rename(remaining_ordinals, axis=1)\n",
    "        return df\n",
    "\n",
    "    data = rename_remaining_ord(data)\n",
    "    eval_data = rename_remaining_ord(eval_data)\n",
    "\n",
    "    target_codes = {\"Yes\": 1, \"No\": 0}\n",
    "\n",
    "    def binarize_target(row):\n",
    "        global target_codes\n",
    "        row[\"target\"] = target_codes[row[\"target\"]]\n",
    "        return row\n",
    "\n",
    "    data = data.apply(binarize_target, axis=1)\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=RandomForestClassifier(\n",
    "            class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        sample_posterior=False,\n",
    "        initial_strategy=\"most_frequent\",\n",
    "        random_state=42,\n",
    "    )\n",
    "    data.isna().sum()\n",
    "    X = data[eval_data.columns]\n",
    "    y = data.target\n",
    "    with parallel_backend(\"threading\", n_jobs=24):\n",
    "        data_enc = imputer.fit_transform(X)\n",
    "        eval_data_enc = imputer.transform(eval_data)\n",
    "\n",
    "    data.loc[:, eval_data.columns] = data_enc\n",
    "    eval_data.loc[:, :] = eval_data_enc\n",
    "    data = data.astype(np.uint32)\n",
    "    eval_data = eval_data.astype(np.uint32)\n",
    "    save_data()\n",
    "else:\n",
    "    data = pd.read_parquet(DATA_OUTPUT + \"data.parquet\")\n",
    "    eval_data = pd.read_parquet(DATA_OUTPUT + \"eval_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ea1d5",
   "metadata": {
    "papermill": {
     "duration": 0.002408,
     "end_time": "2022-09-22T12:45:45.981287",
     "exception": false,
     "start_time": "2022-09-22T12:45:45.978879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data[eval_data.columns]\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6e2e1-7365-4696-b5ca-f4c14cbbbcd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "related_features = (((data.corr().abs() > 0.3).sum(axis=0)) > 1).to_dict()\n",
    "relf = []\n",
    "print(\"Features that have Linear or Non Linear Relationships\\n\\n\".upper())\n",
    "for k, v in related_features.items():\n",
    "    if v:\n",
    "        print(\"\\t\" + k)\n",
    "        relf.append(k)\n",
    "crr = data.corr()\n",
    "relations = {f: {} for f in relf}\n",
    "for f in relf:\n",
    "    f_crr = crr[f].abs()\n",
    "    #     print('\\n')\n",
    "    #     print(f_crr[f_crr > 0.3])\n",
    "    #     print('\\n')\n",
    "    f_rel = crr[f][f_crr[f_crr > 0.3].index].to_dict()\n",
    "    del f_rel[f]\n",
    "    relations[f] = f_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38334774-2d4b-47af-99f6-4f521857094c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nominal = [x for x in eval_data.columns if \"nominal_\" in x]\n",
    "ordinal = [x for x in eval_data.columns if \"ordinal_\" in x]\n",
    "binary = [x for x in eval_data.columns if \"binary_\" in x]\n",
    "len(nominal), len(ordinal), len(binary)\n",
    "X[nominal].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c497f72-d47c-426e-b232-07fbc08de33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nominal__job_industry.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef32b7-2d5f-4233-9481-136ffdfad233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_mutex = PolynomialFeatures(degree=4, include_bias=False, interaction_only=True)\n",
    "poly_mutex.fit(X)\n",
    "poly_f_data = pd.DataFrame(\n",
    "    poly_mutex.transform(X), columns=poly_mutex.get_feature_names_out()\n",
    ")\n",
    "poly_f_eval_data = pd.DataFrame(\n",
    "    poly_mutex.transform(eval_data), columns=poly_mutex.get_feature_names_out()\n",
    ")\n",
    "vr = VarianceThreshold()\n",
    "vr.fit(poly_f_data)\n",
    "poly_f_data = pd.DataFrame(\n",
    "    vr.transform(poly_f_data), columns=vr.get_feature_names_out()\n",
    ")\n",
    "poly_f_eval_data = pd.DataFrame(\n",
    "    vr.transform(poly_f_eval_data), columns=vr.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a4bef-5fc6-4f64-a34f-25db80abb17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_f_data.corrwith(y,method='kendall').abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab150d-deb3-47e9-87cd-9c0c0b9a3757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with parallel_backend(\"threading\", n_jobs=48):\n",
    "    mic = chi2(poly_f_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8020eb1-b1ba-4822-9177-a816373ce5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(mic,'mic_poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d507b4-97f7-4e91-adca-d998303a363b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.plot(mic[0])\n",
    "_ = plt.plot(mic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b284a-c453-434d-a414-bc594c08b709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_poly = np.argsort(mic[0][np.where(mic[0] > (10**5)/4)])\n",
    "good_f = list(poly_f_data.columns[good_poly])\n",
    "\n",
    "print(len(good_f))\n",
    "# for e in good_f:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371d31b-51ff-4a53-a060-cbc39bea8e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = poly_f_data[good_f]\n",
    "y = data.target\n",
    "min_c = poly_f_data[good_f].nunique().astype(\"int\").to_numpy() + 1\n",
    "# clf = RandomForestClassifier(class_weight='balanced',\n",
    "#                              n_jobs=24,\n",
    "# #                              max_features=None,\n",
    "#                              )\n",
    "class_prior = (y.value_counts() / X.shape[0]).sort_index().to_numpy()\n",
    "clf = CategoricalNB(\n",
    "    fit_prior=True,\n",
    "    alpha=0.0000003,\n",
    "    min_categories=min_c,\n",
    "    #                     class_prior=class_prior\n",
    ")\n",
    "categories_ = []\n",
    "for c in X.columns:\n",
    "    categories_.append(sorted(list(X[c].unique())))\n",
    "\n",
    "work = make_pipeline(OrdinalEncoder(categories=categories_), clf)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.5,\n",
    "        random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=y,\n",
    ")\n",
    "with parallel_backend(\"threading\"):\n",
    "    #     scores = cross_validate(clf,X,y,cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42),n_jobs=24,return_train_score=True,scoring='f1_macro')\n",
    "    y_pred = work.fit(X_train, y_train).predict(X_test)\n",
    "    print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe8149-61b8-4bbc-90d2-c10a811864e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = poly_f_data[good_f]\n",
    "y = data.target\n",
    "clf = RandomForestClassifier(\n",
    "    class_weight=\"balanced\", n_jobs=24, max_features=None, max_depth=8\n",
    ")\n",
    "with parallel_backend(\"threading\"):\n",
    "    scores = cross_validate(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42),\n",
    "        n_jobs=24,\n",
    "        return_train_score=True,\n",
    "        scoring=\"f1_macro\",\n",
    "    )\n",
    "_ = plt.plot(scores[\"test_score\"], label=\"TEST\")\n",
    "_ = plt.plot(scores[\"train_score\"], label=\"TRAIN\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447cd39-5d79-4d2e-8ed7-9ad365c840a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_f_data.to_parquet(\"poly_train_4.parquet\", compression=\"brotli\")\n",
    "poly_f_eval_data.to_parquet('poly_eval_4.parquet',compression=\"brotli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ab4b7-67f2-4cac-b09a-c98770e5d252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_f_data = pd.read_parquet(\"poly_train_4.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714bf9a2-66a1-4d29-85eb-4a9298629cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_f_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4013350-3fba-4719-84ae-943e9bbc64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureAgglomeration(n_clusters = 20,affinity=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10c00a-8943-4d92-83e6-ce56876a9ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import phik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50873c50-434c-453e-8440-c046666676e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a569245-7930-4770-abfe-b9910aed70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.compute.use_numba=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4badd38-492e-4c65-9cb9-3142ce9595b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_bins = data.nunique().to_dict()\n",
    "phi = data.global_phik(interval_cols=ordinal,bins=data_bins,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3642b-ccc3-4ed1-add5-b6d86282c700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "baad8963-2fca-4ae6-9272-d80a9a737baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T17:02:40.820397Z",
     "iopub.status.busy": "2022-09-24T17:02:40.819977Z",
     "iopub.status.idle": "2022-09-24T17:02:40.835163Z",
     "shell.execute_reply": "2022-09-24T17:02:40.834398Z",
     "shell.execute_reply.started": "2022-09-24T17:02:40.820351Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nominal__customer_type  binary__has_children\n",
       "0                       0                       3582\n",
       "                        1                       2349\n",
       "1                       1                       1001\n",
       "                        0                        646\n",
       "2                       0                       1090\n",
       "                        1                        529\n",
       "3                       0                       1916\n",
       "                        1                       1266\n",
       "Name: binary__has_children, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('nominal__customer_type')['binary__has_children'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f7d08df-f6b5-4b64-9609-fa006717cd11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T17:00:38.694637Z",
     "iopub.status.busy": "2022-09-24T17:00:38.694222Z",
     "iopub.status.idle": "2022-09-24T17:00:38.703365Z",
     "shell.execute_reply": "2022-09-24T17:00:38.702331Z",
     "shell.execute_reply.started": "2022-09-24T17:00:38.694592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['binary__offer_expiration',\n",
       " 'ordinal__income_range',\n",
       " 'ordinal__no_visited_cold_drinks',\n",
       " 'binary__travelled_more_than_15mins_for_offer',\n",
       " 'ordinal__restaur_spend_less_than20',\n",
       " 'nominal__marital_status',\n",
       " 'nominal__restaurant_type',\n",
       " 'ordinal__age',\n",
       " 'binary__prefer_western_over_chinese',\n",
       " 'binary__travelled_more_than_25mins_for_offer',\n",
       " 'ordinal__no_visited_bars',\n",
       " 'binary__gender',\n",
       " 'nominal__car',\n",
       " 'binary__restuarant_same_direction_house',\n",
       " 'binary__cooks_regularly',\n",
       " 'nominal__customer_type',\n",
       " 'ordinal__qualif',\n",
       " 'binary__is_foodie',\n",
       " 'ordinal__no_take_aways',\n",
       " 'nominal__job_industry',\n",
       " 'binary__restuarant_opposite_direction_house',\n",
       " 'binary__has_children',\n",
       " 'ordinal__rest_rating',\n",
       " 'ordinal__temperature',\n",
       " 'ordinal__restaur_spend_greater_than20',\n",
       " 'ordinal__travel_time',\n",
       " 'nominal__climate',\n",
       " 'nominal__drop_location',\n",
       " 'binary__prefer_home_food']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(eval_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09252005-5175-470d-b095-f1f7447feff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "who = ['binary__gender','ordinal__age',]\n",
    "personal_life = ['nominal__marital_status','binary__has_children','nominal__customer_type']\n",
    "prefe = ['binary__prefer_home_food','binary__is_foodie','binary__prefer_western_over_chinese','binary__cooks_regularly']\n",
    "distance = ['binary__travelled_more_than_15mins_for_offer','binary__travelled_more_than_25mins_for_offer','ordinal__travel_time',]\n",
    "usage_info = ['ordinal__no_visited_cold_drinks','ordinal__restaur_spend_less_than20','ordinal__no_take_aways',]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.640941,
   "end_time": "2022-09-22T12:45:46.908937",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-22T12:45:21.267996",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
